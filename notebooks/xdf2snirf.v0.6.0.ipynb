{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation of an xdf file to snirf format \n",
    "\n",
    "We have the same nirs data in two formats: xdf and snirf. \n",
    "\n",
    "The xdf format is a general format for storing time series data (https://github.com/sccn/xdf). \n",
    "\n",
    "The snirf format is a format for storing nirs data (https://github.com/fNIRS/snirf).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# Flag to run tests and visualizations for each function \n",
    "doRunTests = False\n",
    "\n",
    "if doRunTests: \n",
    "    # define the files to be tested \n",
    "    xdf_fullFile = \"/Users/denismottet/Documents/GitHub/NeuArm-DataAnalysis/data/AgePie/015_AgePie_20211112_1_r(1).xdf\"\n",
    "    xdf_fullFile = \"/Users/denismottet/Documents/GitHub/NeuArm-DataAnalysis/data/ReArm.lnk/twoTestPatientsForOXY4/C1P07_20210802_1_r.xdf\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the xdf file and return only the NIRS and Event streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyxdf\n",
    "\n",
    "\n",
    "def get_NIRS_and_Event_streams(x_file):\n",
    "    \"\"\"\n",
    "    Load the xdf file and returns only the NIRS and Event streams\n",
    "    \"\"\"\n",
    "    # load only the NIRS and Event streams\n",
    "    data, header = pyxdf.load_xdf(\n",
    "        filename=x_file,\n",
    "        select_streams=[{\"type\": \"NIRS\"}, {\"type\": \"Event\"}],\n",
    "        synchronize_clocks=True,\n",
    "        # NOTE: dejitter is necessary to get closer to the oxy4 data\n",
    "        dejitter_timestamps=True,\n",
    "        verbose=False,\n",
    "    )\n",
    "    # find the nirs stream among the list of streams\n",
    "    for i in range(len(data)):\n",
    "        if data[i][\"info\"][\"type\"][0] == \"NIRS\":\n",
    "            nirsStream = data[i]\n",
    "            break\n",
    "    # find the Event stream among the list of streams\n",
    "    for i in range(len(data)):\n",
    "        if data[i][\"info\"][\"type\"][0] == \"Event\":\n",
    "            eventStream = data[i]\n",
    "            break\n",
    "\n",
    "    return nirsStream, eventStream\n",
    "\n",
    "\n",
    "if doRunTests:\n",
    "    # load the xdf file and get the NIRS and Event streams\n",
    "    nirsStream, eventStream = get_NIRS_and_Event_streams(xdf_fullFile)\n",
    "    # print the name and type of each retruned stream\n",
    "    print(\"File: {}\".format(xdf_fullFile))\n",
    "    print(\n",
    "        \"Nirs : {}, {}\".format(\n",
    "            nirsStream[\"info\"][\"name\"][0], nirsStream[\"info\"][\"type\"][0]\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Event: {}, {}\".format(\n",
    "            eventStream[\"info\"][\"name\"][0], eventStream[\"info\"][\"type\"][0]\n",
    "        )\n",
    "    )\n",
    "    # print the number of samples in each stream\n",
    "    print(\"Nirs : {}\".format(nirsStream[\"time_series\"].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reorganize the xdf channels as it is in the corresponding snirf file\n",
    "\n",
    "In the XDF file, we have 34 channels, but only 16 are of interest, i.e., only channels 0 to 7 and 24 to 31 are effectively used for the nirs data that is also present in the snirf file. It seems that the channels are organized in the following way:\n",
    " - channels 0 to 7 are the channels on the left hemisphere\n",
    " - channels 24 to 31 are the channels on the right hemisphere\n",
    "\n",
    "However, in the snirf file, the channels are organized in the following way:\n",
    "- channels with the lowest wavelength first (i.e., 757 nm)\n",
    "- channels with the highest wavelength last (i.e., 852 nm)\n",
    "\n",
    "Moreover, the channels values are stored as a log of the inverse of the intensity.\n",
    "# modify the data according to the ARTINIS matlab code\n",
    "\n",
    "In the ARTINIS matlab code, the data is transformed as follows:\n",
    "```matlab\n",
    "    data.dataTimeSeries = 1./exp(log(10).* [rawvals(:, 2:2:end) rawvals(:, 1:2:end)]); %change dataTimeSeries to correct values\n",
    "```\n",
    " In python, we can do the same thing with the following code:\n",
    "```python\n",
    "    data.dataTimeSeries = 1./np.exp(np.log(10)*np.concatenate((rawvals[:, 1::2], rawvals[:, 0::2]), axis=1))\n",
    "```\n",
    "\n",
    "The key question is why do we need to transform the values to the log of the inverse of the intensity?\n",
    "\n",
    "```python\n",
    "    data.x = 1./np.exp(np.log(10)* x) \n",
    "    # which is equivalent to\n",
    "    data.x = (1.0 / 10.0) ** x\n",
    "```\n",
    "\n",
    "By definition, optical density is $ OD = log_{10}(\\frac{I_0}{I}) $, where $I_0$ is the incident light intensity and $I$ is the transmitted light intensity, \n",
    "\n",
    "As snirf stores the data in the form of optical density, it comes that xdf data is the base 10 logarithm of the inverse of the optical density:  \n",
    "$$ y = [\\frac{1}{10}]^x \\Leftrightarrow \\frac{1}{y} = 10^x \\Leftrightarrow  log_{10}(\\frac{1}{y}) = x $$\n",
    "where $y$ is the optical density and $x$ is the xdf data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_xdf_stream_labels(stream):\n",
    "    \"\"\"\n",
    "    Print the labels of the channels by channel number\n",
    "    \"\"\"\n",
    "\n",
    "    channels = []\n",
    "    for chan in stream[\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"]:\n",
    "        label = chan[\"label\"]\n",
    "        unit = chan[\"unit\"]\n",
    "        type = chan[\"type\"]\n",
    "        channels.append({\"label\": label, \"unit\": unit, \"type\": type})\n",
    "    print(\"Found {} channels: \".format(len(channels)))\n",
    "    for i in range(len(channels)):\n",
    "        print(\n",
    "            \"  {:02d}: {} ({} {})\".format(\n",
    "                i,\n",
    "                channels[i][\"label\"][0][8:],  # remove the first 8 characters\n",
    "                channels[i][\"type\"][0],\n",
    "                channels[i][\"unit\"][0],\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def print_xdf_stream_labels_and_first_last_data(stream):\n",
    "    \"\"\"\n",
    "    Print the labels of the channels + first data value by channel number\n",
    "    \"\"\"\n",
    "    channels = []\n",
    "    for chan in stream[\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"]:\n",
    "        label = chan[\"label\"]\n",
    "        unit = chan[\"unit\"]\n",
    "        type = chan[\"type\"]\n",
    "        channels.append({\"label\": label, \"unit\": unit, \"type\": type})\n",
    "    print(\"Found {} channels: \".format(len(channels)))\n",
    "    for i in range(len(channels)):\n",
    "        print(\n",
    "            \"  {:02d}: {} ({} {}) [{:5.3f}...{:5.3f}]\".format(\n",
    "                i,\n",
    "                channels[i][\"label\"][0][8:],  # remove the first 8 characters\n",
    "                channels[i][\"type\"][0],\n",
    "                channels[i][\"unit\"][0],\n",
    "                stream[\"time_series\"][0, i],\n",
    "                stream[\"time_series\"][-1, i],\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def xdf_reorganize_channels_as_in_snirf(nirsStream):\n",
    "    \"\"\"\n",
    "    Reorganize the xdf stream channels and info/desc0/channels0/ as it is in the snirf file\n",
    "    \"\"\"\n",
    "    # if the stream already has 16 channels, do nothing\n",
    "    if len(nirsStream[\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"]) == 16:\n",
    "        print(\"Stream already has 16 channels\")\n",
    "        return nirsStream\n",
    "\n",
    "    # # modify the data according to the ARTINIS matlab code\n",
    "    # # data.dataTimeSeries = 1./exp(log(10).* [rawvals(:, 2:2:end) rawvals(:, 1:2:end)]);%change dataTimeSeries to correct values\n",
    "    # In the XDF file, we have 34 channels, but only 16 are of interest\n",
    "    # only channels 0 to 7 and 24 to 31 are effectively used\n",
    "    # and the order should be changed to match the snirf file (small wavelength first)\n",
    "\n",
    "    new_order = [\n",
    "        1,\n",
    "        3,\n",
    "        5,\n",
    "        7,\n",
    "        25,\n",
    "        27,\n",
    "        29,\n",
    "        31,\n",
    "        0,\n",
    "        2,\n",
    "        4,\n",
    "        6,\n",
    "        24,\n",
    "        26,\n",
    "        28,\n",
    "        30,\n",
    "    ]\n",
    "\n",
    "    # keep only the 16 channels used and in the snirf order\n",
    "    # NOTE: we do this for the time series AND the channel labels in info/desc0/channels0/\n",
    "    channels = []\n",
    "    time_series = np.zeros((len(nirsStream[\"time_series\"]), len(new_order)))\n",
    "    for i in range(len(new_order)):\n",
    "        iNew = new_order[i]\n",
    "        channels.append(nirsStream[\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"][iNew])\n",
    "        time_series[:, i] = nirsStream[\"time_series\"][:, iNew]\n",
    "\n",
    "    # modify the stream itself\n",
    "    nirsStream[\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"] = channels\n",
    "    nirsStream[\"time_series\"] = time_series\n",
    "\n",
    "    # convert the modified stream to the correct values for snirf\n",
    "    # NOTE: comment out => only change the order of the channels (for verification)\n",
    "    # NOTE: the following two lines are equivalent\n",
    "    # nirsStream[\"time_series\"] = 1.0 / 10.0 ** nirsStream[\"time_series\"]\n",
    "    nirsStream[\"time_series\"] = 1.0 / np.exp(np.log(10) * nirsStream[\"time_series\"])\n",
    "\n",
    "\n",
    "if doRunTests:\n",
    "    xdf_reorganize_channels_as_in_snirf(nirsStream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the events in the marker stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doRunTests:\n",
    "\n",
    "    def get_events_100_111(event_data):\n",
    "        \"\"\"\n",
    "        Find all events containing the word 111 and 100\n",
    "        \"\"\"\n",
    "        i111 = []\n",
    "        i100 = []\n",
    "        for i in range(len(event_data)):\n",
    "            if \"111\" in event_data[i][0]:\n",
    "                i111.append(i)\n",
    "            if \"100\" in event_data[i][0]:\n",
    "                i100.append(i)\n",
    "        print(\"Found {} events 111\".format(len(i111)))\n",
    "        print(\"Found {} events 100\".format(len(i100)))\n",
    "        return i111, i100\n",
    "\n",
    "    event_data = eventStream[\"time_series\"]\n",
    "    event_time = eventStream[\"time_stamps\"]\n",
    "\n",
    "    i111, i100 = get_events_100_111(event_data)\n",
    "\n",
    "    data_111 = []\n",
    "    for i in i111:\n",
    "        print(\"Event {}: {} at {}\".format(i, event_data[i][0][3:], event_time[i]))\n",
    "        data_111.append([event_time[i], 5.0, 1.0])\n",
    "\n",
    "    data_100 = []\n",
    "    for i in i100:\n",
    "        print(\"Event {}: {} at {}\".format(i, event_data[i][0][3:], event_time[i]))\n",
    "        data_100.append([event_time[i], 5.0, 1.0])\n",
    "\n",
    "    stim_data = []\n",
    "    for i in i111:\n",
    "        stim_data.append([event_time[i], 5.0, 1.0])\n",
    "\n",
    "    # make it a numpy array\n",
    "    data_111 = np.array(data_111)\n",
    "    data_100 = np.array(data_100)\n",
    "\n",
    "    print(\"data_111: \", data_111.shape)\n",
    "    print(\"data_100: \", data_100.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the xdf data for the snirf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_xdf_time_relative_to_first_data(nirsStream, eventStream):\n",
    "    \"\"\"\n",
    "    Make the time of the NIRS and Event streams relative to the first data time\n",
    "    As this is in the snirf file\n",
    "    \"\"\"\n",
    "\n",
    "    nirs_time = nirsStream[\"time_stamps\"]\n",
    "    event_time = eventStream[\"time_stamps\"]\n",
    "\n",
    "    # make time relative to the beginning of the recording\n",
    "    t_zero = nirs_time[0]\n",
    "    nirs_time = nirs_time - t_zero\n",
    "    event_time = event_time - t_zero\n",
    "\n",
    "    nirsStream[\"time_stamps\"] = nirs_time\n",
    "    eventStream[\"time_stamps\"] = event_time\n",
    "\n",
    "\n",
    "if doRunTests:\n",
    "    make_xdf_time_relative_to_first_data(nirsStream, eventStream)\n",
    "    print(\"nirs_time: \", nirsStream[\"time_stamps\"].shape)\n",
    "    print(\"nirs_data: \", nirsStream[\"time_series\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy the template snirf file to a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snirf import Snirf\n",
    "import os\n",
    "\n",
    "\n",
    "def copy_snirf_file(file_name, new_file_name):\n",
    "    \"\"\"\n",
    "    Copy the snirf file to a new file using the snirf library\n",
    "    \"\"\"\n",
    "    snirf = Snirf(file_name, \"r\")\n",
    "    snirf.save(new_file_name)\n",
    "    snirf.close()\n",
    "\n",
    "\n",
    "def create_snirf_in_results(xdf_fullFile):\n",
    "    \"\"\"\n",
    "    Create a snirf (template) file named as the xdf file in the results directory\n",
    "    \"\"\"\n",
    "\n",
    "    # get the file name without the path and extension from the xdf file\n",
    "    file_name = os.path.basename(xdf_fullFile)\n",
    "    new_fname = os.path.splitext(file_name)[0] + \".snirf\"\n",
    "\n",
    "    template_file = \"rearm_template.snirf\"\n",
    "    # if the pwd is \"notebooks\", then go up one level to the root directory\n",
    "    if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "        new_fpath = os.path.join(\"..\", \"results\")\n",
    "    elif os.path.basename(os.getcwd()) == \"NeuArm-DataAnalysis\":\n",
    "        new_fpath = os.path.join(\"results\")\n",
    "\n",
    "    new_file_name = os.path.join(new_fpath, new_fname)\n",
    "\n",
    "    copy_snirf_file(template_file, new_file_name)\n",
    "\n",
    "    return new_file_name\n",
    "\n",
    "\n",
    "if doRunTests:\n",
    "    new_fname = create_snirf_in_results(xdf_fullFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify the new snirf file to include the xdf data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_label(labels, i_label_in_events, event_time, label):\n",
    "    \"\"\"\n",
    "    Get the data for a given label\n",
    "    The data is a numpy array with 3 columns: onset, duration, amplitude\n",
    "    https://github.com/BUNPC/pysnirf2/blob/main/docs/pysnirf2.md#class-stimelement\n",
    "    \"\"\"\n",
    "\n",
    "    i_label_in_labels = np.where(labels == label)[0]\n",
    "    i_i_label = np.where(i_label_in_events == i_label_in_labels)[0]\n",
    "    onsets = event_time[i_i_label]\n",
    "    data = np.zeros((len(onsets), 3))\n",
    "    data[:, 0] = onsets\n",
    "    data[:, 1] = 5.0\n",
    "    data[:, 2] = 1.0\n",
    "    return data \n",
    "\n",
    "\n",
    "def print_stim(stim):\n",
    "    print(\"stim: \", stim)\n",
    "    for i in range(len(stim)):\n",
    "        print(stim[i])\n",
    "\n",
    "\n",
    "def print_n_events(stim):\n",
    "    n_events = 0\n",
    "    for i in range(len(stim)):\n",
    "        n_events += len(stim[i].data)\n",
    "    print(\"n_events: \", n_events)\n",
    "    print(\" \")\n",
    "\n",
    "\n",
    "def set_stim(stim, event_data, event_time):\n",
    "    \"\"\"\n",
    "    Set the stim from the event data and event time\n",
    "    \"\"\"\n",
    "    # remove the existing stim data\n",
    "    for i in range(len(stim)):\n",
    "        del stim[0]\n",
    "\n",
    "    # https://numpy.org/doc/stable/reference/generated/numpy.unique.html\n",
    "    labels, i_labels = np.unique(event_data, return_inverse=True)\n",
    "\n",
    "    for label in labels:\n",
    "        stim.appendGroup()\n",
    "        stim[-1].name = label[3:]  # remove the 'L: ' prefix\n",
    "        stim[-1].data = get_data_for_label(labels, i_labels, event_time, label)\n",
    "\n",
    "    return stim  # not necessary (it is pointer), but for clarity during call\n",
    "\n",
    "\n",
    "def modify_snirf_file(new_fname, event_data, event_time, nirs_data, nirs_time):\n",
    "    \"\"\"\n",
    "    Modify the snirf file with the new data and event from the xdf file\n",
    "    \"\"\"\n",
    "    snirf = Snirf(new_fname, \"r+\")\n",
    "    snirf.nirs[0].stim = set_stim(snirf.nirs[0].stim, event_data, event_time)\n",
    "    snirf.nirs[0].data[0].dataTimeSeries = nirs_data\n",
    "    snirf.nirs[0].data[0].time = nirs_time\n",
    "    snirf.save(new_fname)\n",
    "    snirf.close()\n",
    "\n",
    "\n",
    "if doRunTests:\n",
    "    nirs_time = nirsStream[\"time_stamps\"]\n",
    "    event_time = eventStream[\"time_stamps\"]\n",
    "    event_data = eventStream[\"time_series\"]\n",
    "    nirs_data = nirsStream[\"time_series\"]\n",
    "    modify_snirf_file(new_fname, event_data, event_time, nirs_data, nirs_time)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the new snirf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doRunTests:\n",
    "    with Snirf(new_fname, \"r+\") as snirf:\n",
    "        validation_results = snirf.validate()\n",
    "        validation_results.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and plot the new snirf file using the mne library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "\n",
    "if doRunTests:\n",
    "    new = mne.io.read_raw_snirf(new_fname, preload=True, verbose=\"CRITICAL\")\n",
    "    new.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correction of the snirf with mne \n",
    "\n",
    "Tests against the reference markers files showed that one of the two snirf files is not correctly loaded as RAW data by the mne library: it has twice the LSL 111 makers.\n",
    "\n",
    "Here we use the mne library to remove and re-write the markers in the snirf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne_nirs.io import write_raw_snirf\n",
    "\n",
    "def modify_annotations_with_mne (new_fname, event_data, event_time):\n",
    "    new = mne.io.read_raw_snirf(new_fname, preload=True, verbose=\"CRITICAL\")\n",
    "    new.annotations.delete(np.arange(len(new.annotations)))\n",
    "    for i in range(len(event_data)):\n",
    "        description = event_data[i][0][3:]\n",
    "        duration = 5.0\n",
    "        onset = event_time[i]\n",
    "        new.annotations.append(onset, duration, description)\n",
    "    \n",
    "    write_raw_snirf(new, new_fname, add_montage=False)\n",
    "    return new\n",
    "\n",
    "if doRunTests:\n",
    "    # get the name without the path and extension from the xdf file\n",
    "    file_name = os.path.basename(new_fname)\n",
    "    name = os.path.splitext(file_name)[0]\n",
    "\n",
    "    # load the xdf reference file\n",
    "    reference_xMarkers_time = np.genfromtxt(\n",
    "        name + \".reference.xdf_markers.csv\", delimiter=\",\"\n",
    "    )\n",
    "    reference_xMarkers_label = np.genfromtxt(\n",
    "        name + \".reference.xdf_markers.csv\", delimiter=\",\", dtype=\"str\"\n",
    "    )\n",
    "    # remove the first column (time)\n",
    "    reference_xMarkers_label = reference_xMarkers_label[:, 1]\n",
    "    # remove the first 3 characters (L: )\n",
    "    reference_xMarkers_label = np.array([x[3:] for x in reference_xMarkers_label])\n",
    "\n",
    "    # get the annotations from the snirf file\n",
    "    labels = new.annotations.description\n",
    "    onsets = new.annotations.onset\n",
    "\n",
    "    #######################\n",
    "    event_data = eventStream[\"time_series\"]\n",
    "    event_time = eventStream[\"time_stamps\"]\n",
    "    nirs_data = nirsStream[\"time_series\"]\n",
    "    nirs_time = nirsStream[\"time_stamps\"]\n",
    "\n",
    "    new = modify_annotations_with_mne(new_fname, event_data, event_time)\n",
    "\n",
    "    for i in range(len(new.annotations)):\n",
    "        print(new.annotations.description[i], new.annotations.onset[i], new.annotations.duration[i])\n",
    "\n",
    "    new.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion of the xdf to snirf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xdf2snirf(xdf_fullFile):\n",
    "    nirsStream, eventStream = get_NIRS_and_Event_streams(xdf_fullFile)\n",
    "    xdf_reorganize_channels_as_in_snirf(nirsStream)\n",
    "\n",
    "    make_xdf_time_relative_to_first_data(nirsStream, eventStream)\n",
    "    new_fname = create_snirf_in_results(xdf_fullFile)\n",
    "\n",
    "    nirs_time = nirsStream[\"time_stamps\"]\n",
    "    event_time = eventStream[\"time_stamps\"]\n",
    "    event_data = eventStream[\"time_series\"]\n",
    "    nirs_data = nirsStream[\"time_series\"]\n",
    "\n",
    "    modify_snirf_file(new_fname, event_data, event_time, nirs_data, nirs_time)\n",
    "    modify_annotations_with_mne (new_fname, event_data, event_time)\n",
    "    return new_fname\n",
    "\n",
    "if doRunTests:\n",
    "    new_fname = xdf2snirf(xdf_fullFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the exactitude of the new snirf file against the reference data (oxy4 file converted to snirf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference files (snirf and xdf)\n",
    "import os\n",
    "\n",
    "def assert_snirf_file(name, new):   \n",
    "    assert_data(name, new)\n",
    "    assert_markers(name, new)\n",
    "    print(\"assert_snirf_file: \", name, \" OK\")\n",
    "\n",
    "def assert_data(name, new):\n",
    "    # load the snirf reference file\n",
    "    reference_sData = np.loadtxt(name + \".reference.snirf.csv\", delimiter=\",\")\n",
    "    data = new.get_data().T\n",
    "\n",
    "    err = np.max(np.abs(reference_sData - data))\n",
    "    tolerance = 1e-7\n",
    "    assert err < tolerance, \"max abs error = {} is higher than tolerance {}\".format(\n",
    "        err, tolerance\n",
    "    )\n",
    "\n",
    "\n",
    "def assert_markers(name, new):\n",
    "    # load the xdf reference file\n",
    "    reference_xMarkers_time = np.genfromtxt(\n",
    "        name + \".reference.xdf_markers.csv\", delimiter=\",\"\n",
    "    )\n",
    "    reference_xMarkers_label = np.genfromtxt(\n",
    "        name + \".reference.xdf_markers.csv\", delimiter=\",\", dtype=\"str\"\n",
    "    )\n",
    "    # remove the first column (time)\n",
    "    reference_xMarkers_label = reference_xMarkers_label[:, 1]\n",
    "    # remove the first 3 characters (L: )\n",
    "    reference_xMarkers_label = np.array([x[3:] for x in reference_xMarkers_label])\n",
    "\n",
    "    # get the annotations from the snirf file\n",
    "    labels = new.annotations.description\n",
    "    onsets = new.annotations.onset\n",
    "\n",
    "    assert (\n",
    "        reference_xMarkers_time.shape[0] == labels.shape[0]\n",
    "    ), \"Error in xdf file, reference_xMarkers_time.shape[0] = {} != labels.shape[0] = {}\".format(\n",
    "        reference_xMarkers_time.shape[0], labels.shape[0]\n",
    "    )\n",
    "\n",
    "    for i in range(len(reference_xMarkers_time)):\n",
    "        maxTimeError = np.max(\n",
    "            # np.abs(reference_xMarkers_time[i][0] - eventStream[\"time_stamps\"][i])\n",
    "            np.abs(reference_xMarkers_time[i][0] - onsets[i])\n",
    "        )\n",
    "\n",
    "        timeTolerance = 1\n",
    "        assert (\n",
    "            maxTimeError < timeTolerance\n",
    "        ), \"Error in xdf file at index {}, maxTimeError = {} \".format(i, maxTimeError)\n",
    "\n",
    "        assert (\n",
    "            reference_xMarkers_label[i] == labels[i]\n",
    "        ), \"Error in xdf file at index {}, label = {} \".format(\n",
    "            i, reference_xMarkers_label[i][0]\n",
    "        )\n",
    "\n",
    "\n",
    "if doRunTests:\n",
    "\n",
    "    # get the name without the path and extension from the xdf file\n",
    "    file_name = os.path.basename(new_fname)\n",
    "    name = os.path.splitext(file_name)[0]\n",
    "\n",
    "    new = mne.io.read_raw_snirf(new_fname, preload=True, verbose=\"CRITICAL\")\n",
    "\n",
    "    print(\"new_fname: \", new_fname)\n",
    "    assert_snirf_file(name, new)\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
