{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation of an xdf file to snirf format \n",
    "\n",
    "We have the same nirs data in two formats: xdf and snirf. \n",
    "\n",
    "The xdf format is a general format for storing time series data (https://github.com/sccn/xdf). \n",
    "\n",
    "The snirf format is a format for storing nirs data (https://github.com/fNIRS/snirf).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyxdf\n",
    "import os\n",
    "import datetime\n",
    "from dateutil import tz\n",
    "import mne\n",
    "from mne_nirs.io import write_raw_snirf\n",
    "#from snirf import Snirf\n",
    "\n",
    "# Suppress the INFO log messages from mne and snirf\n",
    "import logging\n",
    "logger = logging.getLogger('mne')\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "logger = logging.getLogger('snirf')\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Flag to run tests and visualizations for each function \n",
    "doRunTests = False\n",
    "\n",
    "if doRunTests: \n",
    "    %matplotlib qt\n",
    "\n",
    "    # define the files to be tested \n",
    "    xdf_fullFile = \"../data/reference/015_AgePie_20211112_1_r(1).xdf\"\n",
    "    xdf_fullFile = \"../data/reference/C1P07_20210802_1_r.xdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the xdf file and return only the NIRS and Event streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NIRS_and_Event_streams(x_file):\n",
    "    \"\"\"\n",
    "    Load the xdf file and returns only the NIRS and Event streams\n",
    "    \"\"\"\n",
    "    # load only the NIRS and Event streams\n",
    "\n",
    "    if doRunTests:\n",
    "        # load all the streams and print them\n",
    "        data, header = pyxdf.load_xdf(\n",
    "            filename=x_file,\n",
    "            # select_streams=[{\"type\": \"NIRS\"}, {\"type\": \"Event\"}],\n",
    "            synchronize_clocks=True,\n",
    "            # NOTE: dejitter is necessary to get closer to the oxy4 data\n",
    "            dejitter_timestamps=True,\n",
    "            verbose=False,\n",
    "        )\n",
    "        # list the streams in the file\n",
    "        print(\"Streams in the file:\")\n",
    "        for i in range(len(data)):\n",
    "            print(\n",
    "                \"Stream {}: {} - {}\".format(\n",
    "                    i + 1, data[i][\"info\"][\"name\"][0], data[i][\"info\"][\"type\"][0]\n",
    "                )\n",
    "            )\n",
    "    else:\n",
    "        # load only the NIRS and Event streams\n",
    "        data, header = pyxdf.load_xdf(\n",
    "            filename=x_file,\n",
    "            select_streams=[{\"type\": \"NIRS\"}, {\"type\": \"Event\"}],\n",
    "            synchronize_clocks=True,\n",
    "            # NOTE: dejitter is necessary to get closer to the oxy4 data\n",
    "            dejitter_timestamps=True,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "    # find the nirs stream among the list of streams\n",
    "    for i in range(len(data)):\n",
    "        if data[i][\"info\"][\"type\"][0] == \"NIRS\":\n",
    "            nirsStream = data[i]\n",
    "            break\n",
    "    # find the Event stream among the list of streams\n",
    "    for i in range(len(data)):\n",
    "        if data[i][\"info\"][\"type\"][0] == \"Event\":\n",
    "            eventStream = data[i]\n",
    "            break\n",
    "\n",
    "    return nirsStream, eventStream\n",
    "\n",
    "\n",
    "if doRunTests:\n",
    "    # load the xdf file and get the NIRS and Event streams\n",
    "    nirsStream, eventStream = get_NIRS_and_Event_streams(xdf_fullFile)\n",
    "    # print the name and type of each retruned stream\n",
    "    print(\"File: {}\".format(xdf_fullFile))\n",
    "    print(\n",
    "        \"Nirs : {}, {}\".format(\n",
    "            nirsStream[\"info\"][\"name\"][0], nirsStream[\"info\"][\"type\"][0]\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Event: {}, {}\".format(\n",
    "            eventStream[\"info\"][\"name\"][0], eventStream[\"info\"][\"type\"][0]\n",
    "        )\n",
    "    )\n",
    "    # print the number of samples in each stream\n",
    "    print(\"Nirs : {}\".format(nirsStream[\"time_series\"].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reorganize the xdf channels as it is in the corresponding snirf file\n",
    "\n",
    "In the XDF file, we have 34 channels, but only 16 are of interest, i.e., only channels 0 to 7 and 24 to 31 are effectively used for the nirs data that is also present in the snirf file. It seems that the channels are organized in the following way:\n",
    " - channels 0 to 7 are the channels on the right hemisphere (i.e., S1-D1-757, S1-D1-852, S2-D1-757, S2-D1-852, S3-D1-757, S3-D1-852, S4-D1-757, S4-D1-852)\n",
    " - channels 24 to 31 are the channels on the left hemisphere (i.e, S5-D2-757, S5-D2-852, S6-D2-757, S6-D2-852, S7-D2-757, S7-D2-852, S8-D2-757, S8-D2-852)\n",
    "\n",
    "<img src=\"channels.png\" width=\"500\"/>\n",
    "\n",
    "However, in the snirf file, the channels are organized in the following way:\n",
    "- channels with the lowest wavelength first (i.e., 757 nm)\n",
    "- channels with the highest wavelength last (i.e., 852 nm)\n",
    "\n",
    "Moreover, the data values are not the in same unit in the xdf and snirf files.\n",
    "\n",
    "## modify the data according to the ARTINIS matlab code\n",
    "\n",
    "In the ARTINIS matlab code, the data is transformed as follows:\n",
    "```matlab\n",
    "    data.dataTimeSeries = 1./exp(log(10).* [rawvals(:, 2:2:end) rawvals(:, 1:2:end)]); %change dataTimeSeries to correct values\n",
    "```\n",
    " In python, we can do the same thing with the following code:\n",
    "```python\n",
    "    data.dataTimeSeries = 1./np.exp(np.log(10)*np.concatenate((rawvals[:, 1::2], rawvals[:, 0::2]), axis=1))\n",
    "```\n",
    "\n",
    "This line of code does two things : \n",
    "- it reorganizes the data with the lowest wavelength first (i.e., 757 nm) and the highest wavelength last (i.e., 852 nm)\n",
    "- it transforms the data to the log of the inverse of the intensity\n",
    "\n",
    "The key question is why do we need to transform the values to the log of the inverse of the intensity?\n",
    "\n",
    "```python\n",
    "    data.x = 1./np.exp(np.log(10)* x) \n",
    "    # which is equivalent to\n",
    "    data.x = 1.0 / 10.0 ** x\n",
    "```\n",
    "\n",
    "By definition, optical density is $ OD = log_{10}(\\frac{I_0}{I}) $, where $I_0$ is the incident light intensity and $I$ is the transmitted light intensity.\n",
    "\n",
    "By setting $ I_0 = 1 $, we get: \n",
    "\n",
    "$ OD = log_{10}(\\frac{1}{I}) \\Longleftrightarrow 10^{OD} = \\frac{1}{I} \\Longleftrightarrow  I = \\frac{1}{ 10^{OD}} \\Longleftrightarrow  Â I = [\\frac{1}{ 10}]^{OD} $.\n",
    "\n",
    "So, the transformation is done to get the intensity values from the optical density values.\n",
    "\n",
    "Conclusion:\n",
    "- snirf stores the intensity values (as a percentage of the incident intensity)\n",
    "- xdf stores the optical density values (as the log of the inverse of the intensity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_xdf_stream_labels(stream):\n",
    "    \"\"\"\n",
    "    Print the labels of the channels by channel number\n",
    "    \"\"\"\n",
    "\n",
    "    channels = []\n",
    "    for chan in stream[\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"]:\n",
    "        label = chan[\"label\"]\n",
    "        unit = chan[\"unit\"]\n",
    "        type = chan[\"type\"]\n",
    "        channels.append({\"label\": label, \"unit\": unit, \"type\": type})\n",
    "    print(\"Found {} channels: \".format(len(channels)))\n",
    "    for i in range(len(channels)):\n",
    "        print(\n",
    "            \"  {:02d}: {} ({} {})\".format(\n",
    "                i,\n",
    "                channels[i][\"label\"][0][8:],  # remove the first 8 characters\n",
    "                channels[i][\"type\"][0],\n",
    "                channels[i][\"unit\"][0],\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def print_xdf_stream_labels_and_first_last_data(stream):\n",
    "    \"\"\"\n",
    "    Print the labels of the channels + first data value by channel number\n",
    "    \"\"\"\n",
    "    channels = []\n",
    "    for chan in stream[\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"]:\n",
    "        label = chan[\"label\"]\n",
    "        unit = chan[\"unit\"]\n",
    "        type = chan[\"type\"]\n",
    "        channels.append({\"label\": label, \"unit\": unit, \"type\": type})\n",
    "    print(\"Found {} channels: \".format(len(channels)))\n",
    "    for i in range(len(channels)):\n",
    "        print(\n",
    "            \"  {:02d}: {} ({} {}) [{:5.3f}...{:5.3f}]\".format(\n",
    "                i,\n",
    "                channels[i][\"label\"][0][8:],  # remove the first 8 characters\n",
    "                channels[i][\"type\"][0],\n",
    "                channels[i][\"unit\"][0],\n",
    "                stream[\"time_series\"][0, i],\n",
    "                stream[\"time_series\"][-1, i],\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def xdf_reorganize_channels_as_in_snirf(nirsStream):\n",
    "    \"\"\"\n",
    "    Reorganize the xdf stream channels and info/desc0/channels0/ as it is in the snirf file\n",
    "    \"\"\"\n",
    "    # if the stream already has 16 channels, do nothing\n",
    "    if len(nirsStream[\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"]) == 16:\n",
    "        print(\"Stream already has 16 channels\")\n",
    "        return nirsStream\n",
    "\n",
    "    # # modify the data according to the ARTINIS matlab code\n",
    "    # # data.dataTimeSeries = 1./exp(log(10).* [rawvals(:, 2:2:end) rawvals(:, 1:2:end)]);%change dataTimeSeries to correct values\n",
    "    # In the XDF file, we have 34 channels, but only 16 are of interest\n",
    "    # only channels 0 to 7 and 24 to 31 are effectively used\n",
    "    # and the order should be changed to match the snirf file (small wavelength first)\n",
    "\n",
    "    new_order = [\n",
    "        1,\n",
    "        3,\n",
    "        5,\n",
    "        7,\n",
    "        25,\n",
    "        27,\n",
    "        29,\n",
    "        31,\n",
    "        0,\n",
    "        2,\n",
    "        4,\n",
    "        6,\n",
    "        24,\n",
    "        26,\n",
    "        28,\n",
    "        30,\n",
    "    ]\n",
    "\n",
    "    # keep only the 16 channels used and in the snirf order\n",
    "    # NOTE: we do this for the time series AND the channel labels in info/desc0/channels0/\n",
    "    channels = []\n",
    "    time_series = np.zeros((len(nirsStream[\"time_series\"]), len(new_order)))\n",
    "    for i in range(len(new_order)):\n",
    "        iNew = new_order[i]\n",
    "        channels.append(nirsStream[\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"][iNew])\n",
    "        time_series[:, i] = nirsStream[\"time_series\"][:, iNew]\n",
    "\n",
    "    # modify the stream itself\n",
    "    nirsStream[\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"] = channels\n",
    "    nirsStream[\"time_series\"] = time_series\n",
    "\n",
    "    # convert the modified stream to the correct values for snirf\n",
    "    # NOTE: comment out => only change the order of the channels (for verification)\n",
    "    # NOTE: the following two lines are equivalent\n",
    "    # nirsStream[\"time_series\"] = 1.0 / 10.0 ** nirsStream[\"time_series\"]\n",
    "    nirsStream[\"time_series\"] = 1.0 / np.exp(np.log(10) * nirsStream[\"time_series\"])\n",
    "\n",
    "    # convert the names of the channel to the snirf format\n",
    "    for i in range(len(channels)):\n",
    "        label = nirsStream[\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"][i][\"label\"][0]\n",
    "        label_str = label[8:]  # remove the\n",
    "        tk = label_str.split(\" \")\n",
    "        S = int(tk[2][1:])\n",
    "        D = int(tk[0][2:])\n",
    "        W = int(tk[-1][1:-3])\n",
    "        # sources labels (by half the same)\n",
    "        if i < len(channels) / 2:\n",
    "            S = int(S / 2)\n",
    "        if i >= len(channels) / 2:\n",
    "            S = int((S + 1) / 2)\n",
    "        new_label = \"S{}_D{} {}\".format(S, D, W)\n",
    "        nirsStream[\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"][i][\"label\"][\n",
    "            0\n",
    "        ] = new_label\n",
    "\n",
    "\n",
    "if doRunTests:\n",
    "    xdf_reorganize_channels_as_in_snirf(nirsStream)\n",
    "    channels = nirsStream[\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"]\n",
    "    for i in range(len(channels)):\n",
    "        label = channels[i][\"label\"][0]\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the events in the marker stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doRunTests:\n",
    "\n",
    "    def get_events_100_111(event_data):\n",
    "        \"\"\"\n",
    "        Find all events containing the word 111 and 100\n",
    "        \"\"\"\n",
    "        i111 = []\n",
    "        i100 = []\n",
    "        for i in range(len(event_data)):\n",
    "            if \"111\" in event_data[i][0]:\n",
    "                i111.append(i)\n",
    "            if \"100\" in event_data[i][0]:\n",
    "                i100.append(i)\n",
    "        print(\"Found {} events 111\".format(len(i111)))\n",
    "        print(\"Found {} events 100\".format(len(i100)))\n",
    "        return i111, i100\n",
    "\n",
    "    event_data = eventStream[\"time_series\"]\n",
    "    event_time = eventStream[\"time_stamps\"]\n",
    "\n",
    "    i111, i100 = get_events_100_111(event_data)\n",
    "\n",
    "    data_111 = []\n",
    "    for i in i111:\n",
    "        print(\"Event {}: {} at {}\".format(i, event_data[i][0][3:], event_time[i]))\n",
    "        data_111.append([event_time[i], 5.0, 1.0])\n",
    "\n",
    "    data_100 = []\n",
    "    for i in i100:\n",
    "        print(\"Event {}: {} at {}\".format(i, event_data[i][0][3:], event_time[i]))\n",
    "        data_100.append([event_time[i], 5.0, 1.0])\n",
    "\n",
    "    stim_data = []\n",
    "    for i in i111:\n",
    "        stim_data.append([event_time[i], 5.0, 1.0])\n",
    "\n",
    "    # make it a numpy array\n",
    "    data_111 = np.array(data_111)\n",
    "    data_100 = np.array(data_100)\n",
    "\n",
    "    print(\"data_111: \", data_111.shape)\n",
    "    print(\"data_100: \", data_100.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make xdf time relative to first data, as in snirf format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_xdf_time_relative_to_first_data(nirsStream, eventStream):\n",
    "    \"\"\"\n",
    "    Make the time of the NIRS and Event streams relative to the first data time\n",
    "    As this is in the snirf file\n",
    "    \"\"\"\n",
    "\n",
    "    nirs_time = nirsStream[\"time_stamps\"]\n",
    "    event_time = eventStream[\"time_stamps\"]\n",
    "\n",
    "    # make time relative to the beginning of the recording\n",
    "    t_zero = nirs_time[0]\n",
    "    nirs_time = nirs_time - t_zero\n",
    "    event_time = event_time - t_zero\n",
    "\n",
    "    nirsStream[\"time_stamps\"] = nirs_time\n",
    "    eventStream[\"time_stamps\"] = event_time\n",
    "\n",
    "\n",
    "if doRunTests:\n",
    "    make_xdf_time_relative_to_first_data(nirsStream, eventStream)\n",
    "    print(\"nirs_time: \", nirsStream[\"time_stamps\"].shape)\n",
    "    print(\"nirs_data: \", nirsStream[\"time_series\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the montage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montage for the OXY4\n",
    "dig_points_ReArm_NeuArm = {\n",
    "    \"nz\": [0.400, 85.900, -47.600],\n",
    "    \"a1\": [83.900, -16.600, -56.700],\n",
    "    \"a2\": [-83.800, -18.600, -57.200],\n",
    "    \"cz\": [-0.461, -8.416, 101.365],\n",
    "    \"iz\": [0.200, -120.500, -25.800],\n",
    "    \"S1\": [15.122, 12.567, 92.751],\n",
    "    \"S2\": [55.348, 12.215, 69.807],\n",
    "    \"S3\": [58.686, -30.779, 80.338],\n",
    "    \"S4\": [18.350, -31.372, 101.863],\n",
    "    \"S5\": [-18.221, 14.421, 91.198],\n",
    "    \"S6\": [-57.118, 11.411, 68.420],\n",
    "    \"S7\": [-60.350, -33.460, 78.860],\n",
    "    \"S8\": [-19.193, -31.499, 101.587],\n",
    "    \"D1\": [38.717, -8.599, 90.282],\n",
    "    \"D2\": [-39.835, -9.543, 89.911],\n",
    "}\n",
    "\n",
    "# divide all the coordinates by 1000 to get them in m\n",
    "for key in dig_points_ReArm_NeuArm:\n",
    "    # standard unit are in m\n",
    "    dig_points_ReArm_NeuArm[key] = [x / 1000 for x in dig_points_ReArm_NeuArm[key]]\n",
    "    # standard head is smaller than the one that was recorded\n",
    "    # the 1.08 factor is to have the inter-SD distance of 0.03 m\n",
    "    dig_points_ReArm_NeuArm[key] = [x / 1.08 for x in dig_points_ReArm_NeuArm[key]]\n",
    "\n",
    "\n",
    "def distance(S1, D1):\n",
    "    S1 = np.array(S1[:])\n",
    "    D1 = np.array(D1[:])\n",
    "    distance = np.sqrt(np.sum((D1 - S1) ** 2))\n",
    "    return distance\n",
    "\n",
    "\n",
    "def check_source_detector_distance(dig_points_ReArm_NeuArm):\n",
    "    source_detector_distance = []\n",
    "    for k in [\"S1\", \"S2\", \"S3\", \"S4\"]:\n",
    "        D = dig_points_ReArm_NeuArm[\"D1\"]\n",
    "        S = dig_points_ReArm_NeuArm[k]\n",
    "        source_detector_distance.append(distance(D, S))\n",
    "    for k in [\"S5\", \"S6\", \"S7\", \"S8\"]:\n",
    "        D = dig_points_ReArm_NeuArm[\"D2\"]\n",
    "        S = dig_points_ReArm_NeuArm[k]\n",
    "        source_detector_distance.append(distance(D, S))\n",
    "\n",
    "    # create a figure with two subplots\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    # first subplot on the left half : boxplot of the source-detector distance\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    ax.boxplot(source_detector_distance)\n",
    "    ax.set_title(\"Source-Detector distance\")\n",
    "    ax.set_ylabel(\"Distance (m)\")\n",
    "    # second subplot with a scatter plot of the source-detector distance\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    ax.scatter(range(len(source_detector_distance)), source_detector_distance)\n",
    "    ax.set_ylabel(\"Distance (m)\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def set_dig_montage(channels):\n",
    "    # set the channel locations\n",
    "    montage = mne.channels.make_dig_montage(\n",
    "        ch_pos=channels,\n",
    "        nasion=channels[\"nz\"],\n",
    "        lpa=channels[\"a1\"],\n",
    "        rpa=channels[\"a2\"],\n",
    "        hsp=None,\n",
    "        hpi=None,\n",
    "        coord_frame=\"head\",\n",
    "    )\n",
    "    return montage\n",
    "\n",
    "\n",
    "def set_rearm_dig_montage():\n",
    "    return set_dig_montage(dig_points_ReArm_NeuArm)\n",
    "\n",
    "\n",
    "if doRunTests:\n",
    "    new_montage = set_rearm_dig_montage()\n",
    "    new_montage.plot(show_names=True)\n",
    "\n",
    "    check_source_detector_distance(dig_points_ReArm_NeuArm)\n",
    "\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create snirf in results using the mne library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_and_patientID_from_xdf_file_name(xdf_fullFile):\n",
    "    \"\"\"\n",
    "    Get the date and patient ID from the xdf file name\n",
    "    \"\"\"\n",
    "    # get the file name without the path and extension from the xdf file\n",
    "    file_name = os.path.basename(xdf_fullFile)\n",
    "    tokens = file_name.split(\"_\")\n",
    "    if len(tokens[1]) == 8:  # date\n",
    "        patientID = tokens[0]\n",
    "        date = tokens[1]\n",
    "    elif len(tokens[2]) == 8:  # date\n",
    "        patientID = tokens[0] + \"_\" + tokens[1]\n",
    "        date = tokens[2]\n",
    "    else:\n",
    "        patientID = \"Unknown\"\n",
    "        date = \"Unknown\"\n",
    "\n",
    "    Y = date[0:4]\n",
    "    m = date[4:6]\n",
    "    d = date[6:8]\n",
    "\n",
    "    Y = int(Y)\n",
    "    m = int(m)\n",
    "    d = int(d)\n",
    "\n",
    "    H = 12\n",
    "    M = 0\n",
    "    S = 0\n",
    "\n",
    "    TZ = tz.gettz(\"Europe/Paris\")\n",
    "\n",
    "    date = datetime.datetime(Y, m, d, H, M, S, 0, tzinfo=TZ)\n",
    "\n",
    "    return date, patientID\n",
    "\n",
    "\n",
    "def set_date_and_patientID(raw):\n",
    "    \"\"\"\n",
    "    Set the date and patient ID in the raw mne object\n",
    "    \"\"\"\n",
    "    date, subjectID = get_date_and_patientID_from_xdf_file_name(xdf_fullFile)\n",
    "    raw.info[\"subject_info\"] = {\"first_name\": subjectID}\n",
    "    raw.set_meas_date(date.timestamp())\n",
    "\n",
    "\n",
    "def set_results_path():\n",
    "    # if the pwd is \"notebooks\", then go up one level to the root directory\n",
    "    if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "        # create or use the results directory\n",
    "        new_fpath = os.path.join(\"..\", \"results\")\n",
    "        if not os.path.exists(new_fpath):\n",
    "            os.makedirs(new_fpath)\n",
    "    elif os.path.basename(os.getcwd()) == \"xdf_to_snirf\":\n",
    "        new_fpath = os.path.join(\"results\")\n",
    "    return new_fpath\n",
    "\n",
    "\n",
    "def create_snirf_in_results(xdf_fullFile, nirsStream, eventStream):\n",
    "    \"\"\"\n",
    "    Create a snirf file named as the xdf file in the results directory\n",
    "    \"\"\"\n",
    "\n",
    "    # get the file name without the path and extension from the xdf file\n",
    "    file_name = os.path.basename(xdf_fullFile)\n",
    "    new_fname = os.path.splitext(file_name)[0] + \".snirf\"\n",
    "\n",
    "    new_fpath = set_results_path()\n",
    "    new_file_name = os.path.join(new_fpath, new_fname)\n",
    "\n",
    "    n_channels = nirsStream[\"time_series\"].shape[1]\n",
    "    sampling_freq = nirsStream[\"info\"][\"nominal_srate\"][0]\n",
    "    ch_names = [\n",
    "        n[\"label\"][0] for n in nirsStream[\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"]\n",
    "    ]\n",
    "\n",
    "    nirs_info = mne.create_info(\n",
    "        ch_names=ch_names,\n",
    "        ch_types=\"fnirs_cw_amplitude\",\n",
    "        sfreq=sampling_freq,\n",
    "        verbose=None,\n",
    "    )\n",
    "\n",
    "    # add the wavelength in nirs_info[\"chs\"][0][\"loc\"][9]\n",
    "    for i in range(n_channels):\n",
    "        nirs_info[\"chs\"][i][\"loc\"][9] = int(ch_names[i][-3:])\n",
    "\n",
    "    nirs_info[\"description\"] = \"XDF to SNIRF\"\n",
    "\n",
    "    nirs_data = nirsStream[\"time_series\"].T\n",
    "\n",
    "    raw = mne.io.RawArray(\n",
    "        data=nirs_data,\n",
    "        info=nirs_info,\n",
    "        verbose=None,\n",
    "    )\n",
    "\n",
    "    event_data = eventStream[\"time_series\"]\n",
    "    event_time = eventStream[\"time_stamps\"]\n",
    "\n",
    "    for i in range(len(event_data)):\n",
    "        description = event_data[i][0][3:]\n",
    "        duration = 5.0\n",
    "        onset = event_time[i]\n",
    "        raw.annotations.append(onset, duration, description)\n",
    "\n",
    "    set_date_and_patientID(raw)\n",
    "\n",
    "    raw.set_montage(set_rearm_dig_montage())\n",
    "\n",
    "    write_raw_snirf(raw, new_file_name, add_montage=True)\n",
    "\n",
    "    return new_file_name\n",
    "\n",
    "\n",
    "if doRunTests:\n",
    "    new_fname = create_snirf_in_results(xdf_fullFile, nirsStream, eventStream)\n",
    "    new = mne.io.read_raw_snirf(new_fname, preload=True, verbose=\"CRITICAL\")\n",
    "    new.plot()\n",
    "    new_montage = new.get_montage()\n",
    "    new_montage.plot(show_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the new snirf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doRunTests:\n",
    "    def is_snirf_valid(new_fname):\n",
    "        \"\"\"\n",
    "        Check the snirf file validity\n",
    "        \"\"\"\n",
    "        with Snirf(new_fname, \"r+\") as snirf:\n",
    "            is_valid = snirf.validate()\n",
    "            if not is_valid:\n",
    "                snirf.validation_results.display()\n",
    "        return is_valid\n",
    "\n",
    "\n",
    "    print(\"{} validity: {}\".format(new_fname, is_snirf_valid(new_fname)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and plot the new snirf file using the mne library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doRunTests:\n",
    "    new = mne.io.read_raw_snirf(new_fname, preload=True, verbose=\"CRITICAL\")\n",
    "    new.plot()\n",
    "    print(\"new.info['meas_date']: \", new.info[\"meas_date\"])\n",
    "    print(\"new.info['subject_info']: \", new.info[\"subject_info\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion of the xdf to snirf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xdf2snirf(xdf_fullFile):\n",
    "    nirsStream, eventStream = get_NIRS_and_Event_streams(xdf_fullFile)\n",
    "    xdf_reorganize_channels_as_in_snirf(nirsStream)\n",
    "    make_xdf_time_relative_to_first_data(nirsStream, eventStream)\n",
    "    new_fname = create_snirf_in_results(xdf_fullFile, nirsStream, eventStream)\n",
    "\n",
    "    new = mne.io.read_raw_snirf(new_fname, preload=True, verbose=\"CRITICAL\")\n",
    "    print(f\"Created {new_fname}\")\n",
    "    print(\n",
    "        f\"  {new.info['nchan']} channels, {new.n_times} time points at {new.info['sfreq']} Hz) \"\n",
    "    )\n",
    "    print(\" \")\n",
    "\n",
    "    return new_fname\n",
    "\n",
    "\n",
    "if doRunTests:\n",
    "    new_fname = xdf2snirf(xdf_fullFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the new snirf file again (to see if the markers are correctly loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doRunTests:\n",
    "    with Snirf(new_fname, \"r+\") as snirf:\n",
    "        validation_results = snirf.validate()\n",
    "        validation_results.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the exactitude of the new snirf file against the reference data (oxy4 file converted to snirf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference files (snirf and xdf)\n",
    "import os\n",
    "\n",
    "\n",
    "def assert_snirf_file(name, new):\n",
    "    assert_data(name, new)\n",
    "    assert_markers(name, new)\n",
    "    print(\"assert_snirf_file: \", name, \" OK\")\n",
    "\n",
    "\n",
    "def assert_data(name, new):\n",
    "    # load the snirf reference file\n",
    "    reference_sData = np.loadtxt(name + \".reference.snirf.csv\", delimiter=\",\")\n",
    "    data = new.get_data().T\n",
    "\n",
    "    err = np.max(np.abs(reference_sData - data))\n",
    "    tolerance = 1e-7\n",
    "    assert err < tolerance, \"max abs error = {} is higher than tolerance {}\".format(\n",
    "        err, tolerance\n",
    "    )\n",
    "\n",
    "\n",
    "def assert_markers(name, new):\n",
    "    # load the xdf reference file\n",
    "    reference_xMarkers_time = np.genfromtxt(\n",
    "        name + \".reference.xdf_markers.csv\", delimiter=\",\"\n",
    "    )\n",
    "    reference_xMarkers_label = np.genfromtxt(\n",
    "        name + \".reference.xdf_markers.csv\", delimiter=\",\", dtype=\"str\"\n",
    "    )\n",
    "    # remove the first column (time)\n",
    "    reference_xMarkers_label = reference_xMarkers_label[:, 1]\n",
    "    # remove the first 3 characters (L: )\n",
    "    reference_xMarkers_label = np.array([x[3:] for x in reference_xMarkers_label])\n",
    "\n",
    "    # get the annotations from the snirf file\n",
    "    labels = new.annotations.description\n",
    "    onsets = new.annotations.onset\n",
    "\n",
    "    assert (\n",
    "        reference_xMarkers_time.shape[0] == labels.shape[0]\n",
    "    ), \"Error in xdf file, reference_xMarkers_time.shape[0] = {} != labels.shape[0] = {}\".format(\n",
    "        reference_xMarkers_time.shape[0], labels.shape[0]\n",
    "    )\n",
    "\n",
    "    for i in range(len(reference_xMarkers_time)):\n",
    "        maxTimeError = np.max(\n",
    "            # np.abs(reference_xMarkers_time[i][0] - eventStream[\"time_stamps\"][i])\n",
    "            np.abs(reference_xMarkers_time[i][0] - onsets[i])\n",
    "        )\n",
    "\n",
    "        timeTolerance = 0.1  # one sample shif\n",
    "        assert (\n",
    "            maxTimeError < timeTolerance\n",
    "        ), \"Error in xdf file at index {}, maxTimeError = {} \".format(i, maxTimeError)\n",
    "\n",
    "        assert (\n",
    "            reference_xMarkers_label[i] == labels[i]\n",
    "        ), \"Error in xdf file at index {}, label = {} \".format(\n",
    "            i, reference_xMarkers_label[i][0]\n",
    "        )\n",
    "\n",
    "\n",
    "if doRunTests:\n",
    "    # get the name without the path and extension from the xdf file\n",
    "    file_name = os.path.basename(new_fname)\n",
    "    name = os.path.splitext(file_name)[0]\n",
    "    name = os.path.join(\"../data/reference\", name)\n",
    "\n",
    "    new = mne.io.read_raw_snirf(new_fname, preload=True, verbose=\"CRITICAL\")\n",
    "\n",
    "    print(\"new_fname: \", new_fname)\n",
    "    assert_snirf_file(name, new)\n",
    "\n",
    "    print(\"new.info['meas_date']: \", new.info[\"meas_date\"])\n",
    "    print(\n",
    "        \"new.info['subject_info']['first_name']: \",\n",
    "        new.info[\"subject_info\"][\"first_name\"],\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
